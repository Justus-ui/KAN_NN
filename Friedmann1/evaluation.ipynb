{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Kan_NN' from 'c:\\\\Users\\\\JP\\\\Documents\\\\TU Berlin\\\\Master\\\\Code_clean\\\\Kan_NN.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import Kan_NN\n",
    "import importlib\n",
    "importlib.reload(Kan_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_friedman1\n",
    "def get_loader(in_dim, noise, n_samples = 20000):\n",
    "    # Set the seed for reproducibility\n",
    "    # Generate the Friedmann dataset\n",
    "    #X_train, y = make_friedman1(n_samples= n_samples, n_features=in_dim, noise=noise)\n",
    "    X_train, y = make_friedman1(n_samples= n_samples,n_features = in_dim, noise=noise)\n",
    "    y_train = np.expand_dims(y, axis=1)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "    # Create TensorDataset for train and test sets\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "    # Set batch size and create DataLoader for training and testing\n",
    "    batch_size = n_samples\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_test_loss(test_loader, model):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    running_loss = 0.\n",
    "    for batch, target in test_loader:\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(target, outputs)\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 5 0.0 0.006424714811146259\n",
      "20 5 0.0 0.025810493156313896\n",
      "10 5 0.2 0.005668327212333679\n",
      "20 5 0.2 0.11299943178892136\n",
      "10 5 0.5 0.06980258971452713\n",
      "20 5 0.5 0.025666967034339905\n",
      "10 5 1.0 0.10444386303424835\n",
      "20 5 1.0 0.24955177307128906\n",
      "10 10 0.0 0.0001253562659258023\n",
      "20 10 0.0 7.262809231178835e-05\n",
      "10 10 0.2 0.004242599941790104\n",
      "20 10 0.2 0.009461641311645508\n",
      "10 10 0.5 0.0315709225833416\n",
      "20 10 0.5 0.09040320664644241\n",
      "10 10 1.0 0.20662783086299896\n",
      "20 10 1.0 0.9456732273101807\n",
      "10 15 0.0 0.058137521147727966\n",
      "20 15 0.0 0.08456671237945557\n",
      "10 15 0.2 0.33017322421073914\n",
      "20 15 0.2 0.07598941028118134\n",
      "10 15 0.5 0.18164955079555511\n",
      "20 15 0.5 0.07802418619394302\n",
      "10 15 1.0 0.8277032375335693\n",
      "20 15 1.0 2.722658395767212\n",
      "10 100 0.0 1.8790440559387207\n",
      "20 100 0.0 4.8472161293029785\n",
      "10 100 0.2 2.8806636333465576\n",
      "20 100 0.2 3.898874521255493\n",
      "10 100 0.5 2.5439305305480957\n",
      "20 100 0.5 0.8650254011154175\n",
      "10 100 1.0 3.7147016525268555\n",
      "20 100 1.0 6.5484466552734375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import dill\n",
    "widths = [10,20] ## Grids\n",
    "n_samples = 30000\n",
    "in_dims = [5,10,15,100]\n",
    "noises = [0.,0.2,0.5,1.]\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for in_dim in in_dims:\n",
    "    for noise in noises:\n",
    "        for i,width in enumerate(widths):\n",
    "            test_loader = get_loader(in_dim, noise = 0,n_samples =n_samples)\n",
    "            with open(f\"models/Friedmann_1_KAN_spline_{noise}_{in_dim}.dill\", \"rb\") as f:\n",
    "                model = dill.load(f)\n",
    "            loss = compute_test_loss(test_loader, model[i])\n",
    "            print(width, in_dim, noise, loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
